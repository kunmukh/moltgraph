services:
  neo4j:
    image: neo4j:5
    container_name: moltbook-neo4j
    ports:
      - "7474:7474"   # Browser
      - "7687:7687"   # Bolt
    environment:
      # Install GDS
      - NEO4J_PLUGINS=["graph-data-science"]
      # Recommended so GDS procedures work without permission errors
      - NEO4J_dbms_security_procedures_unrestricted=gds.*
      - NEO4J_dbms_security_procedures_allowlist=gds.*

      # CHANGE THIS
      - NEO4J_AUTH=neo4j/please-change-me
      # Helps when importing large batches
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p please-change-me 'RETURN 1' >/dev/null 2>&1"]
      interval: 10s
      timeout: 10s
      retries: 20

  crawler:
    build: ./crawler
    container_name: moltbook_crawler
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      # Required
      - MOLTBOOK_API_KEY=${MOLTBOOK_API_KEY}
      # Optional (defaults shown)
      - MOLTBOOK_BASE_URL=https://www.moltbook.com/api/v1
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=please-change-me

      # Crawl knobs
      - FETCH_POST_DETAILS=0     # 1 = also GET /posts/:id for every post (slower, richer)
      - SCRAPE_AGENT_HTML=0      # 1 = scrape /u/<agent> for Similar Agents + Human Owner X
      - "USER_AGENT=MoltGraphCrawler/0.1 (research; contact=mkunal@vt.edu)"

      # Rate limiting / politeness
      - REQUESTS_PER_MINUTE=80   # stay below 100/min general limit
    volumes:
      - ./crawler:/app
    command: ["python", "-m", "scripts.weekly_crawl"]

volumes:
  neo4j_data:
  neo4j_logs:
  neo4j_plugins:
